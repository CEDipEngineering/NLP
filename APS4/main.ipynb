{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./db.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isGood(url: str) -> bool:\n",
    "    if url.startswith('https://stackoverflow.com'):\n",
    "        if 'jobs' not in url:\n",
    "            if 'developer' not in url:\n",
    "                if 'directory' not in url:\n",
    "                    return True\n",
    "    return False\n",
    "\n",
    "def find_is_closed(url: str):\n",
    "    if not isGood(url):\n",
    "        return False\n",
    "    user_agent = 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'\n",
    "    headers={'User-Agent':user_agent,} \n",
    "    request=req.Request(url,None,headers) #The assembled request\n",
    "    try:\n",
    "        response = req.urlopen(request, timeout=2)\n",
    "    except Exception as e:\n",
    "        # print(f'{url=} encountered an error {e}')\n",
    "        return False\n",
    "    data = response.read()\n",
    "    soup = bs(data, 'html.parser')\n",
    "    aside = soup.findAll('aside')\n",
    "    if len(aside)<1:\n",
    "        return False\n",
    "    soup_aside = bs(str(aside[0]))\n",
    "    b = soup_aside.find('b')\n",
    "    if not b:\n",
    "        return False\n",
    "    b = b.text.lower()\n",
    "    return ('close' in b or 'answer' in b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPool(12) as pool:\n",
    "    a = pool.map(find_is_closed, df['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cat'] = list(map(int,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('db_cat.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
